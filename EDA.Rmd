---
title: "Predicting Brain Cancer By Gene Expression"
author: "Anna Corcoran, Charlie Konen, Ethan Shang, Kethan Poduri, Daniel Cohen"
date: "2025-12-15"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,   # suppress warnings
  message = FALSE,   # suppress messages
  echo = FALSE       # hide code if desired
)
```

```{r}
#| label: libraries

library(ggplot2)
library(dplyr)
library(tidyverse)
```

```{r}
#| label: load-data

brain <- readRDS("data/brain.rds")

```

## Introduction
Brain cancer is extremely deadly, with a combined estimated 18,330 deaths in the United States in 2025 alone (SEER). Only 40% of adults diagnosed with a malignant brain tumor live for over a year, and less than 20% live for more than 5 years (Penfold). This project covers four types of brain cancer: ependymoma, glioblastoma, medulloblastoma, and pilocytic astrocytoma, with varying severity. Pilocytic astrocytoma is nearly always treatable, with a 96% 5-year survival rate (mayo). Glioblastoma, on the other hand, is incredibly deadly, with a median 5-year survival rate of only 5.6% in adults (ABTA), while medulloblastoma has a median 5-year survival rate of 80.6% (cancer.gov) and ependymoma of nearly 85% (cleveland clinic), making them relatively treatable. Early diagnosis is difficult due to nonspecific symptoms like headaches, weakness, confusion, and memory loss (Penfold) and requires a neurological exam; CT scan, brain MRI and/or PET scan to locate a mass;  and then a brain biopsy and testing of the biopsy in lab to determine if the cells are cancerous (mayo 2). This is lengthy and expensive, delaying accurate prognoses. Brain biopsies are also invasive, requiring a hole to be drilled into the skull and a needle to be inserted into the hole (mayo 2). The goal of this project is to create a model that can accurately predict the state of a sample based on gene expression. This could then be used on circulating tumor DNA (ctDNA), which is cell-free DNA found in the bloodstream, to obtain accurate diagnoses earlier in progression without the invasion of a tumor biopsy (Kim). Early and accurate diagnoses can streamline treatment, getting patients into appropriate clinical trials and improving survival rates. 


```{r}
#| label: EDA
genes <- setdiff(names(brain), c("type", "samples"))

# means
gene_means <- sapply(brain[genes], mean, na.rm = TRUE)

# medians
gene_medians <- sapply(brain[genes], median, na.rm = TRUE)
print 
# standard deviation
gene_sd <- sapply(brain[genes], sd, na.rm = TRUE)

# min
gene_min <- sapply(brain[genes], min, na.rm = TRUE)

# max
gene_max <- sapply(brain[genes], max, na.rm = TRUE)


# summary data frame
gene_summary <- data.frame(
  Gene = names(gene_means),
  Mean = gene_means,
  Median = gene_medians,
  SD = gene_sd,
  Min = gene_min,
  Max = gene_max
)
print(head(gene_summary))
```

```{r}
#| label: histogram-mean
# histograms
# gene means
hist(gene_means,
     breaks = 50,
     main = "Distribution of Gene Means",
     xlab = "Mean Expression",
     col = "lightblue",
     border = "white")
```

```{r}
#| label: histogram-median
# gene medians
hist(gene_medians,
     breaks = 50,
     main = "Distribution of Gene Medians",
     xlab = "Median Expression",
     col = "lightgreen",
     border = "white")
```

```{r}
#| label: histogram-sd   
# standard deviations
hist(gene_sd,
     breaks = 50,
     main = "Distribution of Gene Standard Deviations",
     xlab = "SD",
     col = "lightpink",
     border = "white")
```

```{r}
#| label: top20-hvg
# boxplot of top 20 most variable genes
# Top 20 most variable genes
top_genes <- names(sort(gene_sd, decreasing = TRUE))[1:20]

# Make a bigger plotting window first (optional)
par(mar = c(10, 4, 4, 2) + 0.1)  # bottom margin larger to fit labels
boxplot(brain[top_genes], 
        main = "Top 20 Most Variable Genes", 
        las = 2,       # rotate labels to vertical
        col = "lightcoral",
        cex.axis = 0.7 # shrink label text
)
par(mar = c(5, 4, 4, 2) + 0.1)  # reset margins
```

```{r}
#| label: scatterplot
# scatterplot of gene mean vs sd
plot(gene_means, gene_sd,
     xlab = "Mean Expression",
     ylab = "Standard Deviation",
     main = "Gene Mean vs SD",
     pch = 19, col = rgb(0,0,1,0.5))
```

```{r}
brain %>%
  count(type) %>%
  ggplot(aes(x = type, y = n, fill = type)) +
  geom_col() +
  labs(title = "Sample Counts per Class",
       x = "Brain Tissue Type",
       y = "Count") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}

top5000 <- names(sort(gene_sd, decreasing = TRUE))[1:5000]
pca_res <- prcomp(brain[, top5000], scale. = TRUE)
pca_df <- data.frame(
  PC1 = pca_res$x[,1],
  PC2 = pca_res$x[,2],
  PC3 = pca_res$x[,3],
  type = brain$type
)

ggplot(pca_df, aes(x = PC1, y = PC2, color = type)) +
  geom_point(size = 3, alpha = 0.7) +
  labs(title = "PCA of Brain Gene Expression (Top 5,000 Variable Genes)") +
  theme_minimal()

```

```{r}
overall_summary <- data.frame(
  Metric = c("Mean of Means", "Median of Means", "Mean SD", "Median SD"),
  Value = c(mean(gene_means), median(gene_means),
            mean(gene_sd), median(gene_sd))
)
overall_summary

plot(gene_means, gene_sd,
     xlab = "Mean Expression",
     ylab = "Standard Deviation",
     main = "Gene Mean vs SD",
     pch = 19, col = rgb(0,0,1,0.3))


top20_ids <- names(sort(gene_sd, decreasing = TRUE))[1:20]
points(gene_means[top20_ids], gene_sd[top20_ids],
       pch = 19, col = "red")

```

```{r}
library(glmnet) # for Lasso
library(caret) # for stratified split + confusion matrix
set.seed(325)
```

# Variable Selection - Binary Case

Combine all different types of cancer into one cancer/not cancer binary

```{r}
y_bin <- ifelse(brain$type == "normal", "non_cancer", "cancer")
y_bin <- factor(y_bin, levels = c("non_cancer", "cancer"))

table(y_bin)   # should show two classes now

# Gene matrix (exclude non-gene columns)
genes <- setdiff(names(brain), c("type", "samples"))
X <- as.matrix(brain[, genes])
```

Train/test data

```{r}
#| label: split-80-20
set.seed(325)

train_idx <- createDataPartition(y_bin, p = 0.80, list = FALSE)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y_bin[train_idx]
y_test  <- y_bin[-train_idx]
```

### 3 - fold lasso

-   3 fold because there are only 13 non-sample cancer (what the kaggle
    dataset reccomended)

Choosing lambda:

```{r}
set.seed(325)
K <- 3

fold_id <- createFolds(y_train, k = K, list = FALSE)

cv_fit_bin <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,
  type.measure = "class",
  foldid = fold_id
)

plot(cv_fit_bin)

lambda_min  <- cv_fit_bin$lambda.min
lambda_1se  <- cv_fit_bin$lambda.1se

lambda_min
lambda_1se
```

Extract selected genes / accuracy

```{r}
coef_min <- coef(cv_fit_bin, s = lambda_min)  # dgCMatrix
nonzero_min <- rownames(coef_min)[which(coef_min[, 1] != 0)]
nonzero_min <- setdiff(nonzero_min, "(Intercept)")

coef_1se <- coef(cv_fit_bin, s = lambda_1se) # dgCMatrix
nonzero_1se <- rownames(coef_1se)[which(coef_1se[, 1] != 0)]
nonzero_1se <- setdiff(nonzero_1se, "(Intercept)")

length(nonzero_min)
length(nonzero_1se)

# 3. Make sure response is a clean factor
y_test  <- factor(y_test,  levels = c("non_cancer", "cancer"))
# y_train only needed earlier; you can ensure it there

# 4. Predictions at each lambda
pred_min <- predict(
  cv_fit_bin,
  newx = X_test,
  s = lambda_min,
  type = "class"
)
pred_1se <- predict(
  cv_fit_bin,
  newx = X_test,
  s = lambda_1se,
  type = "class"
)

pred_min  <- factor(as.vector(pred_min),  levels = levels(y_test))
pred_1se  <- factor(as.vector(pred_1se), levels = levels(y_test))

# 5. Accuracies
acc_min <- mean(pred_min == y_test, na.rm = TRUE)
acc_1se <- mean(pred_1se == y_test, na.rm = TRUE)

# 6. Summary table
summary_table_binary <- data.frame(
  Model              = c("Lasso (lambda.min)", "Lasso (lambda.1se)"),
  Lambda             = c(lambda_min, lambda_1se),
  Num_Selected_Genes = c(length(nonzero_min), length(nonzero_1se)),
  Test_Accuracy      = c(acc_min, acc_1se)
)

summary_table_binary
```

```{r}
genes_lasso_1se_binary <- nonzero_1se
genes_lasso_1se_binary
```

2 Strong genes, look at what they actually are:

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("GEOquery")
BiocManager::install("AnnotationDbi")
BiocManager::install("hgu133plus2.db")
```

```{r}
library(Biobase)
library(GEOquery)
library(AnnotationDbi)
library(hgu133plus2.db)   # annotation package for HG-U133 Plus 2.0

probes <- c("214145_s_at", "216073_at")  # your probe IDs

annot <- select(hgu133plus2.db,
               keys = probes,
               columns = c("SYMBOL","ENTREZID","GENENAME"),
               keytype = "PROBEID")

print(annot)
```

Because pairwise gene–gene interactions (epistasis) can play an
important role in tumor biology, we next asked whether the two genes
selected by our initial Lasso model participate in meaningful
interaction effects with other genes. Fitting all pairwise interactions
among \~55,000 genes would require modeling billions of terms and is
computationally infeasible, so we adopted a weak-hierarchy strategy
centered on “anchor” genes. Specifically, we treated the two
Lasso-selected probes (X214145_s_at and X216073_at) as anchors and
constructed a high-dimensional design matrix that included all main
effects for the \~55,000 genes, together with interaction terms between
each anchor gene and every gene in the dataset (i.e., X214145_s_at×G_k
and X216073_at×G_k for all k). We then fit a Lasso-penalized logistic
regression model to this expanded feature set, allowing the penalty to
select a sparse subset of main and interaction effects. This targeted
interaction scan respects weak hierarchy, focuses on interactions
involving genes already implicated by the main-effects model, and
provides a computationally tractable way to screen for potential
epistatic partners of the two anchor genes.

```{r}
genes_all <- setdiff(names(brain), c("type", "samples"))
X_all <- as.matrix(brain[, genes_all])

geneA <- "X214145_s_at"
geneB <- "X216073_at"

A <- X_all[, geneA]
B <- X_all[, geneB]
```

```{r}
set.seed(325)
train_idx <- createDataPartition(y_bin, p = 0.80, list = FALSE)

X_all_train <- X_all[train_idx, ]
X_all_test  <- X_all[-train_idx, ]
y_train <- y_bin[train_idx]
y_test  <- y_bin[-train_idx]
```

```{r}
## Interactions of A with all genes
X_A_int_train <- X_all_train * A[train_idx]
colnames(X_A_int_train) <- paste0(colnames(X_all_train), ":", geneA)

## Interactions of B with all genes
X_B_int_train <- X_all_train * B[train_idx]
colnames(X_B_int_train) <- paste0(colnames(X_all_train), ":", geneB)

## Design matrix: all main effects + all A×G + all B×G + explicit A, B
X_design_train <- cbind(
  X_all_train,
  X_A_int_train,
  X_B_int_train,
  A_anchor = A[train_idx],
  B_anchor = B[train_idx]
)
```

```{r}
X_A_int_test <- X_all_test * A[-train_idx]
colnames(X_A_int_test) <- paste0(colnames(X_all_test), ":", geneA)

X_B_int_test <- X_all_test * B[-train_idx]
colnames(X_B_int_test) <- paste0(colnames(X_all_test), ":", geneB)

X_design_test <- cbind(
  X_all_test,
  X_A_int_test,
  X_B_int_test,
  A_anchor = A[-train_idx],
  B_anchor = B[-train_idx]
)

```

```{r}
set.seed(325)
K <- 3   # safer than 10 given 13 normals

fold_id <- createFolds(y_train, k = K, list = FALSE)

cv_fit_int <- cv.glmnet(
  x = X_design_train,
  y = y_train,
  family = "binomial",
  alpha = 1,
  type.measure = "class",
  foldid = fold_id
)

plot(cv_fit_int)

lambda_min_int <- cv_fit_int$lambda.min
lambda_1se_int <- cv_fit_int$lambda.1se
lambda_min_int
lambda_1se_int
```

```{r}
coef_int_1se <- coef(cv_fit_int, s = lambda_1se_int)

nonzero_1se <- rownames(coef_int_1se)[which(coef_int_1se[, 1] != 0)]
nonzero_1se <- setdiff(nonzero_1se, "(Intercept)")

# All selected interaction terms (contain ":")
selected_interactions <- nonzero_1se[grepl(":", nonzero_1se)]
selected_main_effects <- setdiff(nonzero_1se, selected_interactions)

selected_interactions
selected_main_effects
```

Applying this interaction-augmented Lasso model revealed a focused set
of epistatic candidates. Although the two anchor probes were selected
based on their strong marginal association with cancer status, the
interaction scan showed that only **X216073_at** exhibited evidence of
meaningful combinatorial effects with other genes. Specifically, the
model retained **seven interaction terms**, each representing an
interaction between **X216073_at** and a distinct partner gene
(X1554643_at, X1554771_at, X1556498_at, X1556881_at, X207284_s_at,
X233423_at, and X236037_at). The absence of interaction terms involving
X214145_s_at suggests its contribution to the phenotype is largely
additive, whereas X216073_at may function as an interaction hub whose
joint activity with multiple other genes enhances discrimination between
cancer and normal samples. These retained interaction terms thus
represent prioritized candidates for downstream biological
interpretation and may point toward coordinated regulatory mechanisms
underlying the cancer phenotype.

# Binary Model Selection

# Multinomial Logistic Regression Model 
Plan:
Use the original 5-class type as the multiclass outcome.
Restrict predictors to highly variable genes (HVG candidates) using SD (top 5,000).
Fit a multinomial LASSO (glmnet, family = "multinomial") on those HVGs to select top predictive genes.
From these, choose the top 100 genes (by coefficient magnitude).
Refit a multinomial logistic regression model using only those 100 genes (again via glmnet) and evaluate on a held-out test set.

##HVGs
Setup multiclass response and HVG candidates
```{r}
# Multiclass outcome (5 tissue types)
y_multi <- brain$type
y_multi <- factor(y_multi)  # just to be safe

# Gene matrix (same idea as before)
genes_all <- setdiff(names(brain), c("type", "samples"))
X_all <- as.matrix(brain[, genes_all])

# Highly variable gene candidates: use SD across samples
gene_sd_all <- apply(X_all, 2, sd, na.rm = TRUE)

# Take top 5000 HVGs as candidate set (tune this if needed)
top5000_hvgs <- names(sort(gene_sd_all, decreasing = TRUE))[1:5000]
X_hvg <- X_all[, top5000_hvgs]
```

Train/test split by 5 class type
```{r}
set.seed(325)

train_idx_multi <- createDataPartition(y_multi, p = 0.80, list = FALSE)

X_train_hvg <- X_hvg[train_idx_multi, ]
X_test_hvg  <- X_hvg[-train_idx_multi, ]
y_train_multi <- y_multi[train_idx_multi]
y_test_multi  <- y_multi[-train_idx_multi]
```

Multinomial LASSO to select predictive HVGs
```{r}
set.seed(325)
K <- 3   # small n, so keep folds modest

fold_id_multi <- createFolds(y_train_multi, k = K, list = FALSE)

cv_fit_multi <- cv.glmnet(
  x = X_train_hvg,
  y = y_train_multi,
  family = "multinomial",
  alpha = 1,            # LASSO
  type.measure = "class",
  foldid = fold_id_multi
)

plot(cv_fit_multi)

lambda_min_multi  <- cv_fit_multi$lambda.min
lambda_1se_multi  <- cv_fit_multi$lambda.1se

lambda_min_multi
lambda_1se_multi
```

Pull out nonzero features, keep the top 100 by coefficient magnitude (HVG)
```{r}
# coef() for multinomial returns a list: one matrix per class
coef_list_1se <- coef(cv_fit_multi, s = lambda_1se_multi)

# All features with nonzero coefficient in at least one class
nonzero_features <- unique(unlist(
  lapply(coef_list_1se, function(m) {
    rownames(m)[which(m[, 1] != 0)]
  })
))
nonzero_features <- setdiff(nonzero_features, "(Intercept)")

length(nonzero_features)  # how many genes are nonzero at lambda.1se?

# Rank features by maximum absolute coefficient across classes
coef_abs <- sapply(nonzero_features, function(feat) {
  max(sapply(coef_list_1se, function(m) {
    # guard for any missing names
    if (feat %in% rownames(m)) {
      abs(m[feat, 1])
    } else {
      0
    }
  }))
})

# Sort decreasing and take top 100
if (length(nonzero_features) > 100) {
  top100_features <- names(sort(coef_abs, decreasing = TRUE))[1:100]
} else {
  top100_features <- nonzero_features
}

length(top100_features) #final top 100 HVGs with LASSO
head(top100_features)

```

Fit multinomial logistic regression model with top 100 HVGs
```{r}
# Restrict train/test matrices to the 100 selected genes
X_train_100 <- X_hvg[train_idx_multi, top100_features]
X_test_100  <- X_hvg[-train_idx_multi, top100_features]

set.seed(325)
cv_fit_multi_100 <- cv.glmnet(
  x = X_train_100,
  y = y_train_multi,
  family = "multinomial",
  alpha = 1,
  type.measure = "class"
)

lambda_min_multi_100 <- cv_fit_multi_100$lambda.min
lambda_1se_multi_100 <- cv_fit_multi_100$lambda.1se

lambda_min_multi_100
lambda_1se_multi_100

```

Predictions and performance
```{r}
# Use lambda.1se for a sparser, more stable model
pred_multi <- predict(
  cv_fit_multi_100,
  newx = X_test_100,
  s = lambda_1se_multi_100,
  type = "class"
)

pred_multi <- factor(as.vector(pred_multi), levels = levels(y_train_multi))
y_test_multi <- factor(y_test_multi, levels = levels(y_train_multi))

conf_mat_multi <- confusionMatrix(pred_multi, y_test_multi)
conf_mat_multi

overall_acc_multi <- conf_mat_multi$overall["Accuracy"]
overall_acc_multi

multiclass_summary <- data.frame(
  Lambda          = lambda_1se_multi_100,
  Num_Selected    = length(top100_features),
  Test_Accuracy   = overall_acc_multi
)
multiclass_summary

```
```{r}
conf_mat_multi$table
```
Methodology:
For subtype prediction, we first restricted attention to highly variable genes by computing the standard deviation of each probe across samples and retaining the top 5,000 most variable probes. Using these 5,000 HVGs as predictors and the five-class tissue label as the response (normal plus four tumor subtypes), we fit a LASSO-penalized multinomial logistic regression model via glmnet with 3-fold cross-validation. From the resulting model at the $\lambda.1se$ penalty level, we ranked all nonzero features by the maximum absolute coefficient across classes and selected the top 100 probes as our final HVG feature set. We then refit a multinomial logistic regression model using only these 100 probes and evaluated predictive performance on a held-out test set using overall accuracy and the confusion matrix.

Results:
A sparse multinomial LASSO classifier using only 47 gene expression features achieved 95.8% test accuracy across five brain tissue types. Three tumor subtypes (ependymoma, medulloblastoma, and pilocytic astrocytoma) were classified with perfect sensitivity and specificity. The only misclassifications involved a single glioblastoma sample predicted as normal. This result demonstrates that a low-dimensional gene panel is sufficient for near-perfect discrimination among major pediatric and adult brain tumor classes.

References:
https://seer.cancer.gov/statfacts/html/brain.html 
Penfold C, Joannides AJ, Bell J, Walter FM. Diagnosing adult primary brain tumours: can we do better? Br J Gen Pract. 2017 Jun;67(659):278-279. doi: 10.3399/bjgp17X691277. PMID: 28546414; PMCID: PMC5442949.
https://www.mayoclinic.org/diseases-conditions/astrocytoma/survival-rates/gnc-20591685
https://www.abta.org/tumor_types/glioblastoma-gbm/#:~:text=Prognosis,ages%2040+):%205.6%25*
https://www.cancer.gov/rare-brain-spine-tumor/tumors/medulloblastoma
https://my.clevelandclinic.org/health/diseases/23147-ependymoma
https://www.mayoclinic.org/diseases-conditions/brain-tumor/diagnosis-treatment/drc-20350088
Kim H, Park KU. Clinical Circulating Tumor DNA Testing for Precision Oncology. Cancer Res Treat. 2023 Apr;55(2):351-366. doi: 10.4143/crt.2022.1026. PMID: 36915242; PMCID: PMC10101787. 

